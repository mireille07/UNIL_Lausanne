{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrJWSHLi2pFG"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "\n",
        "\n",
        "\n",
        "import random as r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from transformers import TFCamembertForSequenceClassification, CamembertTokenizer, AutoConfig\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgO-RxlHAGKC",
        "outputId": "33d84e0f-fdc2-4963-d06f-655603059b7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
            "\n",
            "Some layers of TFCamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# (for reproduciblity)\n",
        "r.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "training_data = 'https://raw.githubusercontent.com/LaCrazyTomato/Group-Project-DM-ML-2021/main/data/training_data.csv'\n",
        "\n",
        "df = pd.read_csv(training_data, encoding='utf-8')\n",
        "\n",
        "\n",
        "X = df['sentence'].values # to remove the index\n",
        "y = df['difficulty'].values\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.1,\n",
        "                                                    shuffle=True,\n",
        "                                                    random_state=0)\n",
        "\n",
        "\n",
        "# We need to encode output variable (since they are strings)\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "#y_val = label_encoder.transform(y_val)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "\n",
        "# We define the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "config = AutoConfig.from_pretrained('camembert-base')\n",
        "config.num_labels = 6\n",
        "config.hidden_dropout_prob = 0.1\n",
        "\n",
        "model = TFCamembertForSequenceClassification.from_pretrained('camembert-base',config=config)\n",
        "                                                             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DMJz0yIEXEj",
        "outputId": "4a176cf2-4b3a-40e8-efe8-88636b32f202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            " 921/1080 [========================>.....] - ETA: 1:10:55 - loss: 1.4206 - accuracy: 0.3906"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "  \n",
        "# Tokenize\n",
        "X_train = tokenizer(X_train.tolist(), padding=\"max_length\", truncation=True, return_tensors='tf')\n",
        "X_train = {x: X_train[x] for x in tokenizer.model_input_names}\n",
        "\n",
        "X_test = tokenizer(X_test.tolist(), padding=\"max_length\", truncation=True, return_tensors='tf')\n",
        "X_test = {x: X_test[x] for x in tokenizer.model_input_names}\n",
        "\n",
        "\n",
        "# We will use tensorflow to build and train our model\n",
        "\n",
        "# SETTINGS\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 4\n",
        "\n",
        "# Create tensorflow dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(BATCH_SIZE)\\\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Prepare the model (solver, metrics)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(3e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "# Train\n",
        "es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)\n",
        "lr_cb = tf.keras.callbacks.ReduceLROnPlateau(patience=0, restore_best_weights=True, verbose=1, min_lr=1e-8)\n",
        "csv_cb = tf.keras.callbacks.CSVLogger('history.csv')\n",
        "cp_cb = tf.keras.callbacks.ModelCheckpoint('cp')\n",
        "\n",
        "\n",
        "#model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS,callbacks=[es_cb, lr_cb, csv_cb, cp_cb])\n",
        "model.fit(train_ds,epochs=EPOCHS,callbacks=[es_cb, lr_cb, csv_cb, cp_cb])\n",
        "\n",
        "# Save the tuned model\n",
        "model.save_pretrained('trained_camembert')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}